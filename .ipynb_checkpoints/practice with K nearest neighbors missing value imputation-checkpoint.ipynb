{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   2.]\n",
      " [  2.  nan   4.]\n",
      " [  3.   6.   6.]\n",
      " [ 10.  11.  11.]\n",
      " [ 13.  nan  nan]\n",
      " [ -5.  -9.  -9.]\n",
      " [ -6.  -7.  -7.]\n",
      " [ nan  -8.  -8.]]\n",
      "[[  1.           2.           2.        ]\n",
      " [  2.           4.00600462   4.        ]\n",
      " [  3.           6.           6.        ]\n",
      " [ 10.          11.          11.        ]\n",
      " [ 13.           9.75072189   9.8385891 ]\n",
      " [ -5.          -9.          -9.        ]\n",
      " [ -6.          -7.          -7.        ]\n",
      " [ -5.41641504  -8.          -8.        ]]\n"
     ]
    }
   ],
   "source": [
    "#perform missing data imputation on a screen-by-screen basis,\n",
    "#where a screen is considered to be all screens done in the same day/batch\n",
    "#of cells\n",
    "\n",
    "\"\"\"KNN (k nearest neighbors) missing data imputation using Euclidean distance to select k\n",
    "nearest neighbors and using weight averages for the estimation of the missing value.\n",
    "Missing values are imputed starting with the first column and going down each row in the\n",
    "first column, then repeating with the next column to the right in the data table.\"\"\"\n",
    "#chose 10 nearest neighbors because in a given screen not likely has more than 10 or so hits\n",
    "#and so only about 10 or so neighboring hits would be informative for imputing a putative\n",
    "#hit that is missing a value.  for putative non-hits, there are many neighbors with similar\n",
    "#values and so 10 is still a good number\n",
    "K_NEAREST_NEIGHBORS = 4\n",
    "\n",
    "data_file = open('/Users/markfang/Dropbox/UCSD Grad work/RNA-Yeo Lab/ipython test data/missing values 2.csv', 'rU')\n",
    "data_table = np.genfromtxt(data_file, delimiter=',')\n",
    "\n",
    "print(data_table)\n",
    "\n",
    "numrows = data_table.shape[0]\n",
    "numcols = data_table.shape[1]\n",
    "\n",
    "for j in range(numcols):\n",
    "    for i in range(numrows):\n",
    "        #find missing values by checking for 'nan' value in ndarray\n",
    "        if np.isnan(data_table[i][j]):\n",
    "            #for determining Euclidean distances from the small molecule compound which is\n",
    "            #missing value in 1 replicate to all the other vectors containing data for\n",
    "            #all the other small molecule compounds,\n",
    "            #we ignore the values in the replicate in which there is the missing value\n",
    "            other_vectors = np.delete(data_table, j, axis = 1)\n",
    "            \n",
    "            #initialize the small molecule compound for which\n",
    "            #there is a missing value for 1 replicate; this vector\n",
    "            #will be used as the basis to compare Euclidean distance to the other_vectors\n",
    "            vector_missingval = other_vectors[i:(i + 1), 0:numcols]\n",
    "            \n",
    "            #initialize a vector containing the data in the same repl in which there is\n",
    "            #the missing value; the missing value will be imputed by a weighted average\n",
    "            #of the other data in this replicate\n",
    "            estimating_vals = data_table[0:numrows, j:(j + 1)]\n",
    "            \n",
    "            other_vectors = np.delete(other_vectors, i, axis = 0)\n",
    "            estimating_vals = np.delete(estimating_vals, i, axis = 0)\n",
    "            \n",
    "            nan_estimator_flag = 1\n",
    "            \n",
    "            #remove other rows in which the estimating value is also missing\n",
    "            while(nan_estimator_flag == 1):\n",
    "                nan_estimator_flag = 0\n",
    "                #print(len(estimating_vals))\n",
    "                for x in range(len(estimating_vals)):\n",
    "                    #print(1)\n",
    "                    if (np.isnan(estimating_vals[x])):\n",
    "                        nan_estimator_flag = 1\n",
    "                        row_with_nan = x\n",
    "                        #print(row_with_nan)\n",
    "                \n",
    "                if(nan_estimator_flag == 1):\n",
    "                    other_vectors = np.delete(other_vectors, row_with_nan, axis = 0)\n",
    "                    estimating_vals = np.delete(estimating_vals, row_with_nan, axis = 0)\n",
    "                    #print(other_vectors)\n",
    "                    #print(estimating_vals)\n",
    "            \n",
    "            #the following vector will store the Euclidean distances\n",
    "            euclid_dist = np.zeros((other_vectors.shape[0], 1))\n",
    "\n",
    "            for k in range(other_vectors.shape[0]):\n",
    "                flag_nanvector = 0  \n",
    "                \n",
    "                for l in range(other_vectors.shape[1]):\n",
    "                    if (np.isnan(other_vectors[k][l]) == False) and (np.isnan(vector_missingval[0][l]) == False):\n",
    "                        #calculate Euclidean distance as defined in Troyanskaya et al (2001)\n",
    "                        euclid_dist[k][0] += (other_vectors[k][l] - vector_missingval[0][l]) ** 2\n",
    "                        \n",
    "                        flag_nanvector = 1\n",
    "                \n",
    "                if flag_nanvector == 0:\n",
    "                    #nans are always ranked last\n",
    "                    euclid_dist[k][0] = data_table[i][j]\n",
    "            \n",
    "            #the similarity score calculated below and as defined in Troyanskaya et al (2001)\n",
    "            #will serve as the weights for imputing the missing value based on weighted\n",
    "            #average of the remaining - observed - data in the replicate missing the value\n",
    "            similarity = 1 / euclid_dist\n",
    "            \n",
    "            #rank the other small molecule compounds in terms of their Euclidean distance\n",
    "            #from the small molecule compound with the missing value.  select the k nearest\n",
    "            #neighbors in terms of Euclidean distance\n",
    "            simil_rank = scipy.stats.rankdata(euclid_dist, method = \"ordinal\")\n",
    "            \n",
    "            sum_simil = 0\n",
    "            weighted_avg = 0\n",
    "            for m in range(other_vectors.shape[0]):\n",
    "                if simil_rank[m] <= K_NEAREST_NEIGHBORS:\n",
    "                    sum_simil += similarity[m]\n",
    "                    weighted_avg += similarity[m] * estimating_vals[m]\n",
    "            data_table[i][j] = weighted_avg/sum_simil\n",
    "            \n",
    "            #print(data_table)\n",
    "\n",
    "print(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
